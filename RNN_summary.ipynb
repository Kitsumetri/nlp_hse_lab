{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDFhyOmQan0v"
      },
      "source": [
        "# Text generation with deep learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TslNQEFlan0z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m>>> [2025-02-16 | 01:45:50] logger:70 - WARNING - Log file wasn't created due to file_log=False\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import logging\n",
        "import optuna\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "from src.logger import setup_logger\n",
        "\n",
        "setup_logger(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uB9dp0eman1B"
      },
      "outputs": [],
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, model=\"gru\", n_layers=1, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.model_type = model.lower()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        rnn_class = nn.GRU if self.model_type == \"gru\" else nn.LSTM\n",
        "        self.rnn = rnn_class(\n",
        "            hidden_size, hidden_size, n_layers,\n",
        "            dropout=dropout if n_layers > 1 else 0,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden=None):\n",
        "        batch_size = input.size(0)\n",
        "        encoded = self.encoder(input)\n",
        "        output, hidden = self.rnn(encoded, hidden)\n",
        "        output = self.dropout(output)\n",
        "        decoded = self.decoder(output.contiguous().view(-1, self.hidden_size))\n",
        "        return decoded.view(batch_size, -1, self.output_size), hidden\n",
        "\n",
        "    def init_hidden(self, batch_size, device):\n",
        "        if self.model_type == \"lstm\":\n",
        "            return (\n",
        "                torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)\n",
        "            )\n",
        "        else:\n",
        "            return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VZf7PBqGan1F"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, text, chunk_len=200, stride=50):\n",
        "        self.text = text\n",
        "        self.chunk_len = chunk_len\n",
        "        self.stride = stride\n",
        "        self.unique_chars = sorted(set(text))\n",
        "        self.char_to_idx = {c: i for i, c in enumerate(self.unique_chars)}\n",
        "        self.idx_to_char = {i: c for i, c in enumerate(self.unique_chars)}\n",
        "        self.data = self._process_text()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def _process_text(self):\n",
        "        sequences = []\n",
        "        for i in range(0, len(self.text) - self.chunk_len, self.stride):\n",
        "            chunk = self.text[i:i+self.chunk_len+1]\n",
        "            sequences.append(chunk)\n",
        "        return sequences\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        chunk = self.data[idx]\n",
        "        input_seq = [self.char_to_idx[c] for c in chunk[:-1]]\n",
        "        target_seq = [self.char_to_idx[c] for c in chunk[1:]]\n",
        "        return torch.LongTensor(input_seq), torch.LongTensor(target_seq)\n",
        "    \n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.unique_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_sample(model, dataset, device, prompt=\"The\", max_length=500, temperature=1.0, top_k=10, top_p=0.9):\n",
        "    model.eval()\n",
        "    generated = []\n",
        "    input_seq = torch.LongTensor([dataset.char_to_idx[c] for c in prompt]).unsqueeze(0).to(device)  # (batch=1, seq_len)\n",
        "    hidden = model.init_hidden(1, device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        if len(prompt) > 0:\n",
        "            _, hidden = model(input_seq, hidden)\n",
        "        \n",
        "        input_seq = input_seq[:, -1].unsqueeze(1)\n",
        "        \n",
        "        for _ in range(max_length):\n",
        "            outputs, hidden = model(input_seq, hidden)\n",
        "            logits = outputs[:, -1, :] / temperature  # Берем последний выходной токен\n",
        "            \n",
        "            if top_k > 0:\n",
        "                logits = _top_k_filter(logits, top_k)\n",
        "            if top_p > 0.0:\n",
        "                logits = _top_p_filter(logits, top_p)\n",
        "            \n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            generated.append(next_token.item())\n",
        "            input_seq = next_token\n",
        "    \n",
        "    generated_str = prompt + ''.join([dataset.idx_to_char[idx] for idx in generated])\n",
        "    print(\"\\nGenerated text:\")\n",
        "    print(generated_str)\n",
        "    return generated_str\n",
        "\n",
        "def _top_k_filter(logits, k):\n",
        "    values, _ = torch.topk(logits, k)\n",
        "    min_values = values[:, -1].unsqueeze(1)\n",
        "    return torch.where(logits < min_values, torch.ones_like(logits)*-float('inf'), logits)\n",
        "\n",
        "def _top_p_filter(logits, p):\n",
        "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "    cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "    \n",
        "    sorted_indices_to_remove = cumulative_probs > p\n",
        "    sorted_indices_to_remove[..., 0] = 0\n",
        "    indices_to_remove = sorted_indices_to_remove.scatter(\n",
        "        1, sorted_indices, sorted_indices_to_remove\n",
        "    )\n",
        "    return logits.masked_fill(indices_to_remove, -float('inf'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CharRNN(10, 10, 10).hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            hidden = model.init_hidden(inputs.size(0), device)\n",
        "            outputs, _ = model(inputs, hidden)\n",
        "            loss = criterion(outputs.transpose(1, 2), targets)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "    return total_loss / len(val_loader.dataset)\n",
        "\n",
        "def train_model(model, dataset, epochs=50, batch_size=32, lr=3e-4, trial=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    \n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.encoder.parameters(), 'weight_decay': 0.01},\n",
        "        {'params': model.rnn.parameters()},\n",
        "        {'params': model.decoder.parameters(), 'weight_decay': 0.01}\n",
        "    ], lr=lr, fused=True)\n",
        "    \n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=lr,\n",
        "        total_steps=epochs * len(loader),\n",
        "        pct_start=0.1\n",
        "    )\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scaler = torch.amp.GradScaler()\n",
        "\n",
        "    writer = SummaryWriter(\n",
        "        log_dir=f\"runs/LR_{lr:.6f}-model_type_{model.model_type}-hidden_size_{model.hidden_size}-n_layers_{model.n_layers}-batch_size_{batch_size}\"\n",
        "        )\n",
        "    \n",
        "    best_loss = float('inf')\n",
        "    grad_norms = []\n",
        "    \n",
        "    max_grad_norm = 1.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        progress = tqdm(loader, desc=f\"Epoch {epoch+1}\", leave=False)\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(progress):\n",
        "            current_batch_size = inputs.size(0)\n",
        "            inputs = inputs.to(device, non_blocking=True)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
        "                hidden = model.init_hidden(current_batch_size, device)\n",
        "                outputs, _ = model(inputs, hidden)\n",
        "                loss = criterion(outputs.transpose(1, 2), targets)\n",
        "                l2_reg = sum(p.norm(2) for p in model.parameters())\n",
        "                loss += 0.001 * l2_reg\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(\n",
        "                model.parameters(),\n",
        "                max_norm=max_grad_norm,\n",
        "                norm_type=2,\n",
        "                error_if_nonfinite=False\n",
        "            )\n",
        "            \n",
        "            grad_norms.append(grad_norm.item())\n",
        "            \n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            progress.set_postfix({\n",
        "                'loss': f\"{loss.item():.4f}\",\n",
        "                'grad': f\"{grad_norm:.2f}\",\n",
        "                'lr': f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
        "            })\n",
        "            \n",
        "            if batch_idx % 10 == 0:\n",
        "                writer.add_scalar('Train/Loss', loss.item(), epoch*len(loader)+batch_idx)\n",
        "                writer.add_scalar('Train/Grad_Norm', grad_norm.item(), epoch*len(loader)+batch_idx)\n",
        "                writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch*len(loader)+batch_idx)\n",
        "        \n",
        "        avg_loss = total_loss / len(loader)\n",
        "        writer.add_scalar('Epoch/Loss', avg_loss, epoch)\n",
        "        \n",
        "        logging.info(f\"Epoch {epoch+1}/{epochs} - \"\n",
        "                    f\"Loss: {avg_loss:.4f} - \"\n",
        "                    f\"Grad Norm: {grad_norm:.2f} - \"\n",
        "                    f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "        \n",
        "        # Optuna integration\n",
        "        if trial is not None:\n",
        "            trial.report(avg_loss, epoch)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "        \n",
        "        if avg_loss < best_loss and not torch.isnan(torch.tensor(avg_loss)):\n",
        "            best_loss = avg_loss\n",
        "            torch.save({\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'loss': avg_loss\n",
        "            }, \"best_model.pth\")\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "    \n",
        "    writer.close()\n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'model_type': trial.suggest_categorical('model_type', ['lstm', 'gru']),\n",
        "        'hidden_size': trial.suggest_int('hidden_size', 128, 512),\n",
        "        'n_layers': trial.suggest_int('n_layers', 1, 4),\n",
        "        'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
        "        'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256])\n",
        "    }\n",
        "    \n",
        "    # Load data\n",
        "    df = pd.read_csv('data/arxiv.csv')\n",
        "    text = ' '.join(df['summary'].dropna().values)\n",
        "    dataset = TextDataset(text, chunk_len=250, stride=100)\n",
        "    \n",
        "    # Create model\n",
        "    model = CharRNN(\n",
        "        input_size=dataset.vocab_size,\n",
        "        hidden_size=params['hidden_size'],\n",
        "        output_size=dataset.vocab_size,\n",
        "        model=params['model_type'],\n",
        "        n_layers=params['n_layers'],\n",
        "        dropout=params['dropout']\n",
        "    )\n",
        "    \n",
        "    best_loss = train_model(\n",
        "        model,\n",
        "        dataset,\n",
        "        epochs=10,\n",
        "        batch_size=params['batch_size'],\n",
        "        lr=params['lr'],\n",
        "        trial=trial\n",
        "    )\n",
        "    \n",
        "    return best_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DXnbcOYT36sN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 01:45:51,068] A new study created in memory with name: no-name-6b37bc1c-b4b2-40d2-928f-ce0c65060938\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aae027401f434400882207b33309bece",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:47:22] 693302834:99 - INFO - Epoch 1/10 - Loss: 2.3419 - Grad Norm: 0.11 - LR: 7.48e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87edd318249240fc95fe8ce095fb3bb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:48:50] 693302834:99 - INFO - Epoch 2/10 - Loss: 2.0114 - Grad Norm: 0.09 - LR: 7.26e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c23b2075e02404aa2f5e9fdeaeb9f8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:50:11] 693302834:99 - INFO - Epoch 3/10 - Loss: 1.9910 - Grad Norm: 0.09 - LR: 6.61e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a98f4740653b424c81b32039b67cd716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:51:37] 693302834:99 - INFO - Epoch 4/10 - Loss: 1.9773 - Grad Norm: 0.08 - LR: 5.61e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69e48597b254464997d13148202b598c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:52:52] 693302834:99 - INFO - Epoch 5/10 - Loss: 1.9635 - Grad Norm: 0.08 - LR: 4.39e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "402eaf74e4b24ddba4139cbc3f92adc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:54:05] 693302834:99 - INFO - Epoch 6/10 - Loss: 1.9499 - Grad Norm: 0.08 - LR: 3.09e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbc4d3617a0340afb055353b3f5ab029",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:55:21] 693302834:99 - INFO - Epoch 7/10 - Loss: 1.9360 - Grad Norm: 0.08 - LR: 1.87e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebd241c8b6d74cc398466e9a47cec5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:56:42] 693302834:99 - INFO - Epoch 8/10 - Loss: 1.9236 - Grad Norm: 0.08 - LR: 8.75e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37e4f9977c5547a3aebc897eff71561c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:58:03] 693302834:99 - INFO - Epoch 9/10 - Loss: 1.9136 - Grad Norm: 0.07 - LR: 2.25e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a236e8f122044a1687991db30a129d50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/1133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 01:59:24] 693302834:99 - INFO - Epoch 10/10 - Loss: 1.9079 - Grad Norm: 0.07 - LR: 3.01e-08\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 01:59:24,937] Trial 0 finished with value: 1.9079196999163515 and parameters: {'model_type': 'gru', 'hidden_size': 441, 'n_layers': 1, 'dropout': 0.4858638630439517, 'lr': 0.007484870584147558, 'batch_size': 256}. Best is trial 0 with value: 1.9079196999163515.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb90b99887a244aca77bb1f159908dbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:01:42] 693302834:99 - INFO - Epoch 1/10 - Loss: 2.2286 - Grad Norm: 0.09 - LR: 3.44e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7718cc6426246b4b921cbdb10718c0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:03:59] 693302834:99 - INFO - Epoch 2/10 - Loss: 1.9794 - Grad Norm: 0.09 - LR: 3.33e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bc43fd5a0b44711ae3257753d434010",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:06:22] 693302834:99 - INFO - Epoch 3/10 - Loss: 1.9565 - Grad Norm: 0.20 - LR: 3.04e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd0110553ebe4216a8993614779b77db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:09:13] 693302834:99 - INFO - Epoch 4/10 - Loss: 1.9295 - Grad Norm: 0.20 - LR: 2.58e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b91c9125a0aa4dc983666c056ede591b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:11:44] 693302834:99 - INFO - Epoch 5/10 - Loss: 1.9144 - Grad Norm: 0.15 - LR: 2.02e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5b6ab41e7aa49f18219cee729dcc773",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:13:38] 693302834:99 - INFO - Epoch 6/10 - Loss: 1.9005 - Grad Norm: 0.22 - LR: 1.42e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "292a95a49f1b496c8d544bdd0d084afe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:15:56] 693302834:99 - INFO - Epoch 7/10 - Loss: 1.8875 - Grad Norm: 0.26 - LR: 8.59e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ba7b53f611c4acb99015d55aed5be40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:17:51] 693302834:99 - INFO - Epoch 8/10 - Loss: 1.8755 - Grad Norm: 0.15 - LR: 4.02e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f530ea765c446148b34c49f4e40ca75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:19:53] 693302834:99 - INFO - Epoch 9/10 - Loss: 1.8660 - Grad Norm: 0.12 - LR: 1.04e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7dc5645f1b604b4591e709527cfb2729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/4533 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:21:27] 693302834:99 - INFO - Epoch 10/10 - Loss: 1.8606 - Grad Norm: 0.13 - LR: 1.38e-08\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 02:21:27,387] Trial 1 finished with value: 1.860638885815728 and parameters: {'model_type': 'lstm', 'hidden_size': 474, 'n_layers': 1, 'dropout': 0.3486814559811154, 'lr': 0.0034383992551262907, 'batch_size': 64}. Best is trial 1 with value: 1.860638885815728.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "242a7aa704de48b8822a0967b030cbd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:22:24] 693302834:99 - INFO - Epoch 1/10 - Loss: 3.1395 - Grad Norm: 0.11 - LR: 1.80e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8baf9f08802d4dfa949f62d504613716",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:23:20] 693302834:99 - INFO - Epoch 2/10 - Loss: 2.2835 - Grad Norm: 0.14 - LR: 1.74e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbb7a120c2bf4535b665654f208fc4ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:24:22] 693302834:99 - INFO - Epoch 3/10 - Loss: 2.1471 - Grad Norm: 0.18 - LR: 1.59e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "624de062c08640c2bbdc2113b35c6116",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:25:22] 693302834:99 - INFO - Epoch 4/10 - Loss: 2.0943 - Grad Norm: 0.19 - LR: 1.35e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33877a0842e84da28c07f26f93c9cdd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:26:24] 693302834:99 - INFO - Epoch 5/10 - Loss: 2.0670 - Grad Norm: 0.17 - LR: 1.05e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0191ecf00b854db3a5a15c63bb012f49",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:27:24] 693302834:99 - INFO - Epoch 6/10 - Loss: 2.0512 - Grad Norm: 0.16 - LR: 7.42e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb630e6ceb33476f8cd07834109a118a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:28:24] 693302834:99 - INFO - Epoch 7/10 - Loss: 2.0418 - Grad Norm: 0.15 - LR: 4.49e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07b22b03092d4768a6733e6740f0d3fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:29:25] 693302834:99 - INFO - Epoch 8/10 - Loss: 2.0366 - Grad Norm: 0.15 - LR: 2.10e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a56fd5f73a224f96be53a9b2550de205",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:30:28] 693302834:99 - INFO - Epoch 9/10 - Loss: 2.0339 - Grad Norm: 0.14 - LR: 5.41e-06\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2822e3005d4e4101833d4d9758f3b25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:31:29] 693302834:99 - INFO - Epoch 10/10 - Loss: 2.0331 - Grad Norm: 0.14 - LR: 7.19e-10\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 02:31:30,019] Trial 2 finished with value: 2.0330622869577435 and parameters: {'model_type': 'lstm', 'hidden_size': 321, 'n_layers': 1, 'dropout': 0.320673475556442, 'lr': 0.00017952978220407063, 'batch_size': 128}. Best is trial 1 with value: 1.860638885815728.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54c45ce6a0e14cba824dd78ec8c030f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:32:44] 693302834:99 - INFO - Epoch 1/10 - Loss: 2.8145 - Grad Norm: 0.13 - LR: 2.28e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eebc19144c0e41f9a8a3fd4c0c6f5047",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:33:52] 693302834:99 - INFO - Epoch 2/10 - Loss: 2.0844 - Grad Norm: 0.17 - LR: 2.21e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68740cf8a83247c8a82431a12f1a8ecf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:35:02] 693302834:99 - INFO - Epoch 3/10 - Loss: 1.9933 - Grad Norm: 0.16 - LR: 2.01e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "327fe81339bb434883287a37525982ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:36:14] 693302834:99 - INFO - Epoch 4/10 - Loss: 1.9505 - Grad Norm: 0.18 - LR: 1.71e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad0fe7e89a644334a5a317fe59912f55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:37:22] 693302834:99 - INFO - Epoch 5/10 - Loss: 1.9261 - Grad Norm: 0.16 - LR: 1.34e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4be280e91758462d8cf5777da27066a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:38:24] 693302834:99 - INFO - Epoch 6/10 - Loss: 1.9117 - Grad Norm: 0.16 - LR: 9.40e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c0f3a6612e644c0863cd73c5011124e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:39:26] 693302834:99 - INFO - Epoch 7/10 - Loss: 1.9029 - Grad Norm: 0.15 - LR: 5.69e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28843d88130148e5989ac13e6cce4808",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:40:28] 693302834:99 - INFO - Epoch 8/10 - Loss: 1.8976 - Grad Norm: 0.15 - LR: 2.66e-05\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "905b4d2850904acc86fe35ff80665aa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:41:29] 693302834:99 - INFO - Epoch 9/10 - Loss: 1.8948 - Grad Norm: 0.16 - LR: 6.86e-06\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2498f0140c974e9393433ff2aad215e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:42:30] 693302834:99 - INFO - Epoch 10/10 - Loss: 1.8937 - Grad Norm: 0.15 - LR: 9.12e-10\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 02:42:30,692] Trial 3 finished with value: 1.89370472533242 and parameters: {'model_type': 'gru', 'hidden_size': 509, 'n_layers': 1, 'dropout': 0.11791046128873349, 'lr': 0.00022762592761211306, 'batch_size': 128}. Best is trial 1 with value: 1.860638885815728.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c36424bc99246beb6b6ebba8a7e92b8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:43:47] 693302834:99 - INFO - Epoch 1/10 - Loss: 2.8181 - Grad Norm: 0.12 - LR: 3.56e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8e0e64548c940449137bcfbfdd3139e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:45:03] 693302834:99 - INFO - Epoch 2/10 - Loss: 2.3175 - Grad Norm: 0.11 - LR: 3.46e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "017812b7c5b84f5cbf210357031dd646",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:46:20] 693302834:99 - INFO - Epoch 3/10 - Loss: 2.2899 - Grad Norm: 0.12 - LR: 3.15e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59536fbd8df14e778946fbf2e4a4fc0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:47:36] 693302834:99 - INFO - Epoch 4/10 - Loss: 2.2759 - Grad Norm: 0.11 - LR: 2.67e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b50bade99d54b26ad4b1274a28e075b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:48:53] 693302834:99 - INFO - Epoch 5/10 - Loss: 2.2643 - Grad Norm: 0.11 - LR: 2.09e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edd53309da944a30a238663df211bdb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:50:10] 693302834:99 - INFO - Epoch 6/10 - Loss: 2.2542 - Grad Norm: 0.11 - LR: 1.47e-03\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8768051480749bf97538f81254c7bd6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:51:28] 693302834:99 - INFO - Epoch 7/10 - Loss: 2.2448 - Grad Norm: 0.11 - LR: 8.91e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19edab968393435bbb4b4365a7d61d66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:52:44] 693302834:99 - INFO - Epoch 8/10 - Loss: 2.2370 - Grad Norm: 0.11 - LR: 4.17e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b3832da22154879871e106470a023e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:53:59] 693302834:99 - INFO - Epoch 9/10 - Loss: 2.2314 - Grad Norm: 0.11 - LR: 1.07e-04\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdc27be516fe4650ab02e00dcf063ff3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/2266 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m>>> [2025-02-16 | 02:55:16] 693302834:99 - INFO - Epoch 10/10 - Loss: 2.2285 - Grad Norm: 0.11 - LR: 1.43e-08\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-02-16 02:55:16,484] Trial 4 finished with value: 2.2285121556203764 and parameters: {'model_type': 'gru', 'hidden_size': 134, 'n_layers': 4, 'dropout': 0.44910169818021606, 'lr': 0.0035647419550270004, 'batch_size': 128}. Best is trial 1 with value: 1.860638885815728.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_type</th>\n",
              "      <th>hidden_size</th>\n",
              "      <th>n_layers</th>\n",
              "      <th>dropout</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lstm</td>\n",
              "      <td>474</td>\n",
              "      <td>1</td>\n",
              "      <td>0.348681</td>\n",
              "      <td>0.003438</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model_type  hidden_size  n_layers   dropout        lr  batch_size\n",
              "0       lstm          474         1  0.348681  0.003438          64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50, timeout=3600)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "best_trial = study.best_trial\n",
        "pd.DataFrame([best_trial.params])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
