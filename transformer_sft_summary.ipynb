{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-15 11:08:21 __init__.py:190] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel # API –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "max_seq_length = 4096\n",
    "max_summary_length = 256\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–∏–Ω–∞–π–∑–µ—Ä\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-0.5B\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.9 patched 24 layers with 24 QKV layers, 24 O layers and 24 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Lora\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–∞–∑–æ–≤—ã–π alpaca prompting –¥–ª—è SFT\n",
    "alpaca_prompt = \"\"\"–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –∑–∞–¥–∞–Ω–∏–µ, –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –≤–≤–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –¥–∞–ª—å–Ω–µ–π—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º –≤—ã–ø–æ–ª–Ω–∏—Ç –∑–∞–ø—Ä–æ—Å.\n",
    "\n",
    "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n",
    "{}\n",
    "\n",
    "### –í–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "{}\n",
    "\n",
    "### –û—Ç–≤–µ—Ç:\n",
    "{}\"\"\"\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞—á—É \"–†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞\"\n",
    "EOS_TOKEN = tokenizer.eos_token # –∫–æ–Ω–µ—á–Ω—ã–π —Ç–æ–∫–µ–Ω —É —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ Qwen\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    # –°–æ–∑–¥–∞—ë–º —Å—ç–º–ø–ª –ø–æ —à–∞–±–ª–æ–Ω–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É, –≤ –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        text = alpaca_prompt.format(\"–†–µ–∑—é–º–∏—Ä—É–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω—ë–º –≤ –∫—Ä–∞—Ç–∫–æ–º –æ–±—ä—ë–º–µ.\", input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets # —Ä–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏ HF\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "def prepare_sets(ds_repo: str, name: str, revision: str, split: str):\n",
    "    ds = load_dataset(ds_repo, name=name, revision=revision, split=split) # –∑–∞–≥—Ä—É–∑–∫–∞ —Å —Å–µ—Ä–≤–µ—Ä–∞\n",
    "    ds = ds.remove_columns([x for x in ds.column_names if x not in ('text', 'summary')]) # —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "    ds = ds.rename_columns({\"text\": \"input\", \"summary\": \"output\"})  # –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –ø–æ–¥ –æ–±—â–∏–π —Ñ–æ—Ä–º–∞—Ç\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ:\n",
    "    ds = ds.filter(\n",
    "        lambda x: \n",
    "            len(x[\"input\"]) >= 512 and # 1) –¥–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ >= 512 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x[\"input\"]) <= max_seq_length and  # 2) –¥–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ <= 4096\n",
    "            len(x[\"output\"]) >= 20 and # 3) –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç >= 20 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x['output']) <= max_summary_length and  # 4) –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç <= 128 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x[\"output\"])/len(x[\"input\"]) < 0.3  # 5) –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä—ë–º–æ–≤ 2-—Ö —Ç–µ–∫—Å—Ç–æ–≤ <= 0.3\n",
    "    )\n",
    "\n",
    "    if split == 'test': # –ø—Ä–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        return ds\n",
    "    \n",
    "    ds = ds.map(formatting_prompts_func, batched=True) # –≤ –∏–Ω–æ–º —Å–ª—É—á–∞–µ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –¥–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ <= 4096 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    ds = ds.filter(\n",
    "        lambda x: len(x[\"text\"]) <= max_seq_length,\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f8a4efbe7c4ab28bad4d5d379026b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/60964 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71589e0ebb354c90bf8fafde3b7a26cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913ea06636484d4f802865e8734a5692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/9662 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5384c746d41a4efd847bbf1694e0d94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6369 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8db0995114e4a9fb4b557114e671c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ef9fde600e4893acf4afade86c6876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/678 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782d8fa8a2a3429eb3746e3c2fb9ce4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/62243 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5420a1e56c834a36a891d881a37cfa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e539657f0a94e64ad124536100d2a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/30641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88cb0dea04d46729bae51498f1bb441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "404f26203e394741a1073e1b0982fc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede9904fd66e451190bb155a394bde35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408cbdbd8b844586956fffa68f235fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/6793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ef56613b3645ec9adf93f3b22ee56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7780 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = concatenate_datasets(\n",
    "    [\n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='train'), \n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='validation'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='train'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='validation')\n",
    "    ]\n",
    ")\n",
    "test_dataset = concatenate_datasets(\n",
    "    [\n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='test'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='test')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input', 'output', 'text'],\n",
       "     num_rows: 38413\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input', 'output'],\n",
       "     num_rows: 5520\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í–∑–≥–ª—è–µ–º –Ω–∞ –æ–±—ä—ë–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–í –ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥–µ –Ω–∞ 82-–º –≥–æ–¥—É –∂–∏–∑–Ω–∏ —Å–∫–æ–Ω—á–∞–ª—Å—è —Å–æ–≤–µ—Ç—Å–∫–∏–π –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–π –¥–µ—Ç—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –í–ª–∞–¥–∏—Å–ª–∞–≤ –ö—Ä–∞–ø–∏–≤–∏–Ω. –û–± —ç—Ç–æ–º —Å–æ–æ–±—â–∏–ª–∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ –ú–∏–Ω–∑–¥—Ä–∞–≤–∞ —Ä–µ–≥–∏–æ–Ω–∞. ¬´–î–∞. –°–µ–≥–æ–¥–Ω—è¬ª, ‚Äî —Ü–∏—Ç–∏—Ä—É–µ—Ç –ø—Ä–µ—Å—Å-—Å–ª—É–∂–±—É –ú–∏–Ω–∑–¥—Ä–∞–≤–∞ –†–ò–ê ¬´–ù–æ–≤–æ—Å—Ç–∏¬ª. –°–æ–≥–ª–∞—Å–Ω–æ –Ω–µ–≤–µ—Å—Ç–∫–µ –ö—Ä–∞–ø–∏–≤–∏–Ω–∞ –õ–∞—Ä–∏—Å–µ, –ø–∏—Å–∞—Ç–µ–ª—å —É–º–µ—Ä —É—Ç—Ä–æ–º 1 —Å–µ–Ω—Ç—è–±—Ä—è –ø–æ –º–µ—Å—Ç–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏. ¬´–£–º–µ—Ä –≤ 06:40. –ï–º—É —Å—Ç–∞–ª–æ —Ö—É–∂–µ, –Ω–æ—á—å—é –æ—Ç–≤–µ–∑–ª–∏ –≤ —Ä–µ–∞–Ω–∏–º–∞—Ü–∏—é ‚Äî –∏ –≤—Å–µ¬ª, ‚Äî –ø–µ—Ä–µ–¥–∞–µ—Ç –µ–µ —Å–ª–æ–≤–∞ –¢–ê–°–°. –†–∞–Ω–µ–µ –õ–∞—Ä–∏—Å–∞ –≤ —Å–≤–æ–µ–º Facebook —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–ª–∞, —á—Ç–æ –ö—Ä–∞–ø–∏–≤–∏–Ω –±—ã–ª –≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω 15 –∏—é–ª—è. –ö–∞–∫ —Ç–æ–≥–¥–∞ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–ª–∞ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏—Ü–∞, —Ä–µ—à–µ–Ω–∏–µ –æ–± –æ—Ç–ø—Ä–∞–≤–∫–µ –ø–∏—Å–∞—Ç–µ–ª—è –≤ –≥–æ—Å–ø–∏—Ç–∞–ª—å –±—ã–ª–æ –ø—Ä–∏–Ω—è—Ç–æ –Ω–∞ —Ñ–æ–Ω–µ —Ç–æ–≥–æ, —á—Ç–æ –æ–Ω ¬´–≤–Ω–µ–∑–∞–ø–Ω–æ —É–ø–∞–ª —É—Ç—Ä–æ–º, –≤—Å—Ç–∞–≤ —Å –∫—Ä–æ–≤–∞—Ç–∏¬ª. ¬´–û–Ω –±—ã–ª –≤ —Å–æ–∑–Ω–∞–Ω–∏–∏, —Ö–æ—Ç—è –∏ –ø–ª–æ—Ö–æ —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞–ª. –ò –±—ã–ª–æ –æ—â—É—â–µ–Ω–∏–µ, —á—Ç–æ —ç—Ç–æ –∏–Ω—Å—É–ª—å—Ç. –ë—ã–ª–∞ —Å—Ä–æ—á–Ω–æ –≤—ã–∑–≤–∞–Ω–∞ —Å–∫–æ—Ä–∞—è –ø–æ–º–æ—â—å. [–í –±–æ–ª—å–Ω–∏—Ü–µ –µ–º—É] —Å–¥–µ–ª–∞–ª–∏ –ö–¢ –≥–æ–ª–æ–≤–Ω–æ–≥–æ –º–æ–∑–≥–∞ –∏ –ª–µ–≥–∫–∏—Ö, –∫–∞—Ä–¥–∏–æ–≥—Ä–∞–º–º—É –∏ –∞–Ω–∞–ª–∏–∑ –∫—Ä–æ–≤–∏, —Å–µ–º—å–µ –±—ã–ª–æ —Å–∫–∞–∑–∞–Ω–æ, —á—Ç–æ –∏–Ω—Å—É–ª—å—Ç–∞ –∏ –∏–Ω—Ñ–∞—Ä–∫—Ç–∞ –Ω–µ—Ç, –Ω–æ –µ—Å—Ç—å –ø–æ–¥–æ–∑—Ä–µ–Ω–∏–µ –Ω–∞ COVID, –ø–æ—Ç–æ–º—É —á—Ç–æ –ö–¢ –ª–µ–≥–∫–∏—Ö –ø–æ–∫–∞–∑–∞–ª–∞ –Ω–∞–ª–∏—á–∏–µ –ø–Ω–µ–≤–º–æ–Ω–∏–∏ —Å 25% –ø–æ—Ä–∞–∂–µ–Ω–∏—è¬ª, ‚Äî –ø–æ–¥—á–µ—Ä–∫–Ω—É–ª–∞ –Ω–µ–≤–µ—Å—Ç–∫–∞ –∞–≤—Ç–æ—Ä–∞. –û–Ω–∞ —Ç–∞–∫–∂–µ –æ—Ç–º–µ—Ç–∏–ª–∞, —á—Ç–æ –ö—Ä–∞–ø–∏–≤–∏–Ω, —Ç–µ—Å—Ç—ã –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω–∞ –∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –±—ã–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º–∏, –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –ø—Ä–æ–≤–µ–ª –≤ COVID-–æ—Ç–¥–µ–ª–µ–Ω–∏–∏. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –∂–µ–Ω—â–∏–Ω–∞ –≤—ã—Ä–∞–∑–∏–ª–∞ –º–Ω–µ–Ω–∏–µ, —á—Ç–æ –≤—Ä–∞—á–∏ ¬´–ø—Ä–æ—Å–º–æ—Ç—Ä–µ–ª–∏ [—É –ø–∏—Å–∞—Ç–µ–ª—è] –∏–Ω—Å—É–ª—å—Ç, –∫–æ—Ç–æ—Ä—ã–π, –≤–∏–¥–∏–º–æ, –≤—Å–µ-—Ç–∞–∫–∏ —Å–ª—É—á–∏–ª—Å—è¬ª. –°–æ–≥–ª–∞—Å–Ω–æ —Ä–æ–¥—Å—Ç–≤–µ–Ω–Ω–∏—Ü–µ, –∑–Ω–∞–º–µ–Ω–∏—Ç—ã–π –∞–≤—Ç–æ—Ä –±—ã–ª –≤—ã–ø–∏—Å–∞–Ω –∏–∑ –±–æ–ª—å–Ω–∏—Ü—ã 7 –∞–≤–≥—É—Å—Ç–∞, –ø—Ä–∏ —ç—Ç–æ–º –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –±—ã–ª–æ ¬´–Ω–∞–º–Ω–æ–≥–æ —Ö—É–∂–µ, —á–µ–º —Ç—Ä–∏ –Ω–µ–¥–µ–ª–∏ –Ω–∞–∑–∞–¥¬ª. ¬´–û–Ω –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤–æ–æ–±—â–µ –Ω–µ –º–æ–∂–µ—Ç –¥–≤–∏–≥–∞—Ç—å—Å—è. –£ –Ω–µ–≥–æ –Ω–∞ –Ω–æ–≥–µ –æ–≥—Ä–æ–º–Ω–∞—è –≥–µ–º–∞—Ç–æ–º–∞ ‚Äî –∏ –≤—Å—è –Ω–æ–≥–∞ —Å–∏–Ω—è—è. –í —Ä–∞–π–æ–Ω–µ –ø–∞—Ö–∞ –±–æ–ª—å—à–∞—è —à–∏—à–∫–∞. –ù–∞ —Å–ø–∏–Ω–µ –ø—Ä–æ–ª–µ–∂–Ω–∏. –í—Å–µ —ç—Ç–æ –≤—ã–∑—ã–≤–∞–µ—Ç –∞–¥—Å–∫—É—é –±–æ–ª—å –∏ –º—É—á–µ–Ω–∏—è. –û–Ω –≤—Å–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å–∏—Ç –ø–∏—Ç—å. –ï—Å—Ç —Å –±–æ–ª—å—à–∏–º —Ç—Ä—É–¥–æ–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –∏–¥–µ—Ç —Ä–≤–æ—Ç–∞. –° –Ω–∞–º–∏ –æ–±—â–∞–µ—Ç—Å—è, –Ω–æ –±–æ–ª—å—à–µ —Å–ø–∏—Ç¬ª, ‚Äî –¥–µ–ª–∏–ª–∞—Å—å –õ–∞—Ä–∏—Å–∞ 9 –∞–≤–≥—É—Å—Ç–∞. –£–∂–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å –ø–∏—Å–∞—Ç–µ–ª—å –±—ã–ª –≤–Ω–æ–≤—å –≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ê 12 –∞–≤–≥—É—Å—Ç–∞ –ö—Ä–∞–ø–∏–≤–∏–Ω—É –±—ã–ª–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏—è: ¬´–ì–æ–≤–æ—Ä—è—Ç, —á—Ç–æ –∏–∑ –Ω–æ–≥–∏ —Ö–∏—Ä—É—Ä–≥–∏ –æ—Ç–∫–∞—á–∞–ª–∏ 1,5 –ª–∏—Ç—Ä–∞ –Ω–µ—Ö–æ—Ä–æ—à–µ–π —Å–∫–æ–ø–∏–≤—à–µ–π—Å—è –∂–∏–¥–∫–æ—Å—Ç–∏¬ª. –í–ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–∏ –õ–∞—Ä–∏—Å–∞ –ø–∏—Å–∞–ª–∞, —á—Ç–æ –ø–æ—Å–ª–µ –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–≥–æ —É—Ö—É–¥—à–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –ö—Ä–∞–ø–∏–≤–∏–Ω –ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª —Å–µ–±—è –ª—É—á—à–µ. –í–º–µ—Å—Ç–µ —Å —Ç–µ–º 31 –∞–≤–≥—É—Å—Ç–∞ –∂–µ–Ω—â–∏–Ω–∞, —Å—Å—ã–ª–∞—è—Å—å –Ω–∞ –≤—Ä–∞—á–µ–π, –∑–∞—è–≤–∏–ª–∞ Ura.Ru , —á—Ç–æ –ø–∏—Å–∞—Ç–µ–ª—å –≤—Å–µ –∂–µ –ø–µ—Ä–µ–±–æ–ª–µ–ª –∫–æ—Ä–æ–Ω–∞–≤–∏—Ä—É—Å–æ–º, –∫–æ—Ç–æ—Ä—ã–π –∏ ¬´—Å–ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞–ª –æ—Å–ª–æ–∂–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö –±–æ–ª—è—á–µ–∫, –≤–∫–ª—é—á–∞—è –¥–∏–∞–±–µ—Ç, —Å–µ—Ä–¥—Ü–µ –∏ –∏–Ω—Å—É–ª—å—Ç—ã¬ª. –ü–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –ø—Ä–∏—á–∏–Ω–æ–π —Å–º–µ—Ä—Ç–∏ –∞–≤—Ç–æ—Ä–∞ —Å—Ç–∞–ª–æ –æ–±–æ—Å—Ç—Ä–µ–Ω–∏–µ —Ö—Ä–æ–Ω–∏—á–µ—Å–∫–∏—Ö –±–æ–ª–µ–∑–Ω–µ–π –Ω–∞ —Ñ–æ–Ω–µ COVID-19. –°–æ–±–æ–ª–µ–∑–Ω–æ–≤–∞–Ω–∏—è –≤ —Å–≤—è–∑–∏ —Å –∫–æ–Ω—á–∏–Ω–æ–π –ø–∏—Å–∞—Ç–µ–ª—è –≤—ã—Ä–∞–∑–∏–ª –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä –°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –ï–≤–≥–µ–Ω–∏–π –ö—É–π–≤–∞—à–µ–≤. ¬´–≠—Ç–æ —Ç—è–∂–µ–ª–∞—è, —Å–∫–æ—Ä–±–Ω–∞—è, –Ω–µ–≤–æ—Å–ø–æ–ª–Ω–∏–º–∞—è —É—Ç—Ä–∞—Ç–∞ –¥–ª—è –≤—Å–µ—Ö –Ω–∞—Å. –í–ª–∞–¥–∏—Å–ª–∞–≤ –ö—Ä–∞–ø–∏–≤–∏–Ω —à–∏—Ä–æ–∫–æ –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫ –∞–≤—Ç–æ—Ä –∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –¥–ª—è –¥–µ—Ç–µ–π –∏ —é–Ω–æ—à–µ—Å—Ç–≤–∞. –ü–æ—á—Ç–∏ –≤ –∫–∞–∂–¥–æ–π —Ä–æ—Å—Å–∏–π—Å–∫–æ–π —Å–µ–º—å–µ –µ—Å—Ç—å –∫–Ω–∏–≥–∏ –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –ü–µ—Ç—Ä–æ–≤–∏—á–∞, —É—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏–µ –∏–¥–µ–∞–ª—ã –¥–æ–±—Ä–∞ –∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏, –ø—Ä–æ–Ω–∏–∫–Ω—É—Ç—ã–µ –¥—É—Ö–æ–º —Ä–æ–º–∞–Ω—Ç–∏–∑–º–∞ –∏ –ø—Ä–∏–∫–ª—é—á–µ–Ω–∏–π, –ø–æ–¥–Ω–∏–º–∞—é—â–∏–µ –≤–∞–∂–Ω–µ–π—à–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–µ –∏ –Ω—Ä–∞–≤—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã, ‚Äî –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–∞ –ø–æ—Ä—Ç–∞–ª–µ –≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä–∞. ‚Äî –í–ª–∞–¥–∏—Å–ª–∞–≤–∞ –ü–µ—Ç—Ä–æ–≤–∏—á–∞ –ö—Ä–∞–ø–∏–≤–∏–Ω–∞ –≤—Å–µ–≥–¥–∞ –±—É–¥—É—Ç –ø–æ–º–Ω–∏—Ç—å, –∫–∞–∫ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ —Ç–∞–ª–∞–Ω—Ç–ª–∏–≤–æ–≥–æ, —á–µ—Å—Ç–Ω–æ–≥–æ, –Ω–µ—Ä–∞–≤–Ω–æ–¥—É—à–Ω–æ–≥–æ –∫–æ –≤—Å—è–∫–æ–π –Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫–∞. –ò–º –≤–æ—Å—Ö–∏—â–∞–ª–∏—Å—å, –µ–º—É –≤–µ—Ä–∏–ª–∏, –µ–≥–æ —É–≤–∞–∂–∞–ª–∏ –∏ –ª—é–±–∏–ª–∏¬ª. –í–ª–∞–¥–∏—Å–ª–∞–≤ –ö—Ä–∞–ø–∏–≤–∏–Ω —Ä–æ–¥–∏–ª—Å—è 14 –æ–∫—Ç—è–±—Ä—è 1938 –≥–æ–¥–∞ –≤ –¢—é–º–µ–Ω–∏. –ù–∞ –µ–≥–æ —Å—á–µ—Ç—É —Ç–∞–∫–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è, –∫–∞–∫ ¬´–ú–∞–ª—å—á–∏–∫ —Å–æ —à–ø–∞–≥–æ–π¬ª, ¬´–ñ—É—Ä–∞–≤–ª–µ–Ω–æ–∫ –∏ –º–æ–ª–Ω–∏–∏¬ª, ¬´–¢—Ä–æ–µ —Å –ø–ª–æ—â–∞–¥–∏ –ö–∞—Ä—Ä–æ–Ω–∞–¥¬ª, ¬´–ö–æ–ª—ã–±–µ–ª—å–Ω–∞—è –¥–ª—è –±—Ä–∞—Ç–∞¬ª –∏ ¬´–ë–æ–ª—Ç–∏–∫¬ª, —Ä–∞–±–æ—Ç—ã –∞–≤—Ç–æ—Ä–∞ —Ç–∞–∫–∂–µ –Ω–µ–æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ —ç–∫—Ä–∞–Ω–∏–∑–∏—Ä–æ–≤–∞–ª–∏—Å—å. –ü–æ–º–∏–º–æ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ö—Ä–∞–ø–∏–≤–∏–Ω –∏–∑–≤–µ—Å—Ç–µ–Ω –∫–∞–∫ –ø–µ–¥–∞–≥–æ–≥: –≤ –Ω–∞—á–∞–ª–µ 1960-—Ö –æ–Ω –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–ª –≤ –°–≤–µ—Ä–¥–ª–æ–≤—Å–∫–µ –¥–µ—Ç—Å–∫–∏–π –æ—Ç—Ä—è–¥ ¬´–ö–∞—Ä–∞–≤–µ–ª–ª–∞¬ª, –∫–æ—Ç–æ—Ä—ã–º –≤–ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–∏ —Ä—É–∫–æ–≤–æ–¥–∏–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏–π.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['input'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    max_seq_length = max_seq_length,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        overwrite_output_dir = True,\n",
    "        num_train_epochs = 3,\n",
    "        per_device_train_batch_size = 32,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        learning_rate = 3e-4,\n",
    "        logging_steps = 10,\n",
    "        \n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.01,\n",
    "        max_grad_norm = 0.8,\n",
    "        \n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        \n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    "        save_steps=200,\n",
    "        torch_compile=True,\n",
    "        gradient_checkpointing=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4070 Ti. Max memory = 11.994 GB.\n",
      "0.547 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 38,413 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 128 | Total steps = 900\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Enabled auto compiling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 3:34:59, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.817900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.800700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.794600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.787900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.775100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.744900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.739400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.723600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.706800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.681900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.669600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.673100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.680100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.673200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen2_5_lora_sft_model/tokenizer_config.json',\n",
       " 'qwen2_5_lora_sft_model/special_tokens_map.json',\n",
       " 'qwen2_5_lora_sft_model/vocab.json',\n",
       " 'qwen2_5_lora_sft_model/merges.txt',\n",
       " 'qwen2_5_lora_sft_model/added_tokens.json',\n",
       " 'qwen2_5_lora_sft_model/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä\n",
    "model.save_pretrained(\"qwen2_5_lora_sft_model\")\n",
    "tokenizer.save_pretrained(\"qwen2_5_lora_sft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12916.6526 seconds used for training.\n",
      "215.28 minutes used for training.\n",
      "Peak reserved memory = 4.072 GB.\n",
      "Peak reserved memory for training = 3.525 GB.\n",
      "Peak reserved memory % of max memory = 33.95 %.\n",
      "Peak reserved memory for training % of max memory = 29.39 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory*100, 3)\n",
    "\n",
    "\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_txt: str, _model, _tokenizer):\n",
    "    _model = FastLanguageModel.for_inference(_model)\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –±–∞—Ç—á –¥–ª–∏–Ω–Ω–æ–π 1 –∏–∑ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏, \"–û—Ç–≤–µ—Ç: \" –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—à–∫–∏\n",
    "    inputs = _tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"–†–µ–∑—é–º–∏—Ä—É–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω—ë–º –≤ –∫—Ä–∞—Ç–∫–æ–º –æ–±—ä—ë–º–µ.\",\n",
    "            input_txt,\n",
    "            \"\",\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏–º –≤—ã—Ö–ª–æ–ø –º–æ–¥–µ–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ù–µ –∑–∞–±—ã–≤–∞–µ–º –¥–µ–ª–∞—Ç—å split, —á—Ç–æ–±—ã –Ω–µ –≤—ã–≤–æ–¥–∏—Ç—å –≤–µ—Å—å –ø—Ä–æ–º–ø—Ç\n",
    "    outputs = _model.generate(input_ids = inputs.input_ids, attention_mask = inputs.attention_mask,\n",
    "                            max_new_tokens=max_summary_length, use_cache=True)\n",
    "    return _tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].split(\"### –û—Ç–≤–µ—Ç:\\n\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# –ì—Ä—É–∑–∏–º –±–∞–∑–æ–≤—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "model_base, tokenizer_base = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-0.5B\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")\n",
    "\n",
    "# –ì—Ä—É–∑–∏–º SFT –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "model_sft, tokenizer_sft = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"qwen2_5_lora_sft_model\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "SFT model: \n",
      "--------------------------------------------------\n",
      "('–ü–æ–ª–∏—Ü–∏—è –£–∫—Ä–∞–∏–Ω—ã –∑–∞–¥–µ—Ä–∂–∞–ª–∞ –ø–æ–ª–∏—Ç–∏–∫–∞ –ú–∏—Ö–∞–∏–ª–∞ –°–∞–∞–∫–∞—à–≤–∏–ª–∏, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±–≤–∏–Ω—è—é—Ç –≤ '\n",
      " '—Å–æ–¥–µ–π—Å—Ç–≤–∏–∏ –ø—Ä–µ—Å—Ç—É–ø–Ω—ã–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º –∏ –ø–æ—Å—è–≥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—É—é '\n",
      " '—Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –£–∫—Ä–∞–∏–Ω—ã.')\n",
      "--------------------------------------------------\n",
      "Base model: \n",
      "--------------------------------------------------\n",
      "('–ü–æ—Å–ª–µ –∑–∞–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–ª–∏—Ç–∏–∫–∞ –°–∞–∞–∫–∞—à–≤–∏–ª–∏ –≤ –∫–∏–µ–≤—Å–∫–æ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ \"–°—É–ª—É–≥—É–Ω–∏\" –±—ã–ª '\n",
      " '–∑–∞–¥–µ—Ä–∂–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –±—É—Å, –∑–∞—Ç–µ–º –ø–æ–≤–µ–∑–ª–∏ –∏ –∑–∞—Ç–µ–º –ø–æ—Å–∞–¥–∏–ª–∏ –≤ –≤–µ—Ä—Ç–æ–ª–µ—Ç. '\n",
      " '–í–µ—Ä—Ç–æ–ª–µ—Ç, –∫–∞–∫ —è –ø–æ–Ω–∏–º–∞—é, –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∫—Ä—É–∂–∏–ª –Ω–∞–¥ –ö–∏–µ–≤–æ–º. –ü–æ—Å–ª–µ —á–µ–≥–æ '\n",
      " '–ø—Ä–∏–∑–µ–º–ª–∏–ª—Å—è –≤ –ë–æ—Ä–∏—Å–ø–æ–ª–µ, –≥–¥–µ –º–µ–Ω—è, —Å–∫—Ä—É—Ç–∏–≤ —Ä—É–∫–∏ –∏ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –≥—Ä—É–±–æ–π —Å–∏–ª—ã, '\n",
      " '–ø–æ—Å–∞–¥–∏–ª–∏ –≤ —Å–∞–º–æ–ª–µ—Ç.')\n",
      "--------------------------------------------------\n",
      "Ground truth: \n",
      "--------------------------------------------------\n",
      "('–ë—ã–≤—à–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –ì—Ä—É–∑–∏–∏ –∏ —ç–∫—Å-–≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä –û–¥–µ—Å—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –£–∫—Ä–∞–∏–Ω—ã –ú–∏—Ö–∞–∏–ª '\n",
      " '–°–∞–∞–∫–∞—à–≤–∏–ª–∏, –∫–æ—Ç–æ—Ä—ã–π –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ –≤—ã—Å—Ç—É–ø–∞–µ—Ç —Å –∫—Ä–∏—Ç–∏–∫–æ–π –≤ –∞–¥—Ä–µ—Å '\n",
      " '—É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –ü–µ—Ç—Ä–∞ –ü–æ—Ä–æ—à–µ–Ω–∫–æ, –≤—ã—Å–ª–∞–Ω –∏–∑ –ö–∏–µ–≤–∞ –≤ –ü–æ–ª—å—à—É.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint # –∫—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥\n",
    "from random import choice # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–Ω–¥–æ–º–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "# –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —Å—ç–º–ø–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "random_idx = choice(range(0, len(test_dataset)))\n",
    "random_text = test_dataset['input'][random_idx]\n",
    "random_output = test_dataset['output'][random_idx]\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —É 2-—Ö –º–æ–¥–µ–ª–µ–π\n",
    "predicted_output_pretrained = inference(random_text, model_sft, tokenizer_sft)\n",
    "predicted_output_base = inference(random_text, model_base, tokenizer_base)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –≤—ã—Ö–ª–æ–ø–∞ –º–æ–¥–µ–ª–µ–π –∏ ground truth\n",
    "print('-' * 50)\n",
    "print(\"SFT model: \")\n",
    "print('-' * 50)\n",
    "pprint(predicted_output_pretrained)\n",
    "\n",
    "print('-' * 50)\n",
    "print(\"Base model: \")\n",
    "print('-' * 50)\n",
    "pprint(predicted_output_base)\n",
    "\n",
    "print('-' * 50)\n",
    "print('Ground truth: ')\n",
    "print('-' * 50)\n",
    "pprint(random_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é SFT —è –≤ —Ü–µ–ª–æ–º –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º:\n",
    "1) –ú–æ–¥–µ–ª—å –Ω–∞—É—á–∏–ª–∞—Å—å —Å–ª–µ–¥–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç—É –ø—Ä–æ–º–ø—Ç–æ–≤\n",
    "2) –õ—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç\n",
    "3) –£–ª–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–∏\n",
    "4) –•–æ—Ç—å –æ—Ç–≤–µ—Ç—ã –∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç GT, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –≥–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°—Ä–∞–≤–Ω–∏–≤–∞—è –±–∞–∑–æ–≤—ã–π **Qwen2.5-0.5B** –∏ **SFT Qwen2.5-0.5B**:\n",
    "* –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–æ–≤–æ–ª—å–Ω–æ –ø–ª–æ—Ö–æ —Å–ª–µ–¥—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏ –Ω–µ –¥–µ–ª–∞–µ—Ç —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ —á–∞—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ—Ç—Å—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º –ø–æ –¥–ª–∏–Ω–µ —Å—Ç—Ä–æ–∫–∏. –ù–µ —Å–æ–±–ª—é–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–∞, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç. –ë—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–∏, –µ—Å–ª–∏ –Ω–µ —Å—Ç–∞–≤–∏—Ç—å –±–æ–ª—å—à–æ–π ```reputatuin_penality```.\n",
    "\n",
    "* –í —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å SFT –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç —Å–≤–æ—é –∑–∞–¥–∞—á—É, –¥–µ–ª–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –∏ —Å–æ–±–ª—é–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞. –í—Å–µ–≥–¥–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ù–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.\n",
    "\n",
    "## –ì–æ–≤–æ—Ä—è –æ –ø–ª—é—Å–∞—Ö SFT –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:\n",
    "1) –ú–∞–ª–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM (—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏)\n",
    "2) –î–æ–≤–æ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (—Å–ø–∞—Å–∏–±–æ, –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –æ—Ç unsloth)\n",
    "3) –ù–µ—Ç—Ä–µ–±–æ–≤–∞—Ç–µ–ª—å–Ω–∞ –∫ gold-–¥–∞–Ω–Ω—ã–º, —Ç–∞–∫ –∫–∞–∫ —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—Ç–∏—Ç –º–æ–¥–µ–ª—å, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø–æ–ª–µ–∑–Ω–∞—è –¥–∞—Ç–∞ –±—É—Å—Ç–∏—Ç –º–æ–¥–µ–ª—å.\n",
    "\n",
    "## –ì–æ–≤–æ—Ä—è –æ –º–∏–Ω—É—Å–∞—Ö SFT –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:\n",
    "1) –ù—É–∂–Ω–æ –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ –∏ –¥–ª—è –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–∫)\n",
    "2) –ü–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π RL –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Å–ª–µ SFT (–Ω–∞–ø—Ä–∏–º–µ—Ä PPO/GRPO –∏ –ø—Ä–æ—á–∏–µ policy) –≤—Ä—è–¥ –ª–∏ –≤—ã–π–¥–µ—Ç.\n",
    "3) –õ—É—á—à–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–µ–±—è LLM –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —Ö–æ—Ç—è –±—ã —Å >1.5B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±—ã—Å—Ç—Ä–µ–µ —É–ª–∞–≤–ª–∏–≤–∞—é—Ç –∑–∞–¥–∞—á—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
