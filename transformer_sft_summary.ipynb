{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 02-15 03:14:11 __init__.py:190] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel # API –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "max_seq_length = 4096\n",
    "max_summary_length = 256\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–∏–Ω–∞–π–∑–µ—Ä\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-0.5B\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.9 patched 24 layers with 24 QKV layers, 24 O layers and 24 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ Lora\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–∞–∑–æ–≤—ã–π alpaca prompting –¥–ª—è SFT\n",
    "alpaca_prompt = \"\"\"–ù–∏–∂–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è, –æ–ø–∏—Å—ã–≤–∞—é—â–∞—è –∑–∞–¥–∞–Ω–∏–µ, –≤ —Å–æ—á–µ—Ç–∞–Ω–∏–∏ —Å –≤–≤–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –¥–∞–ª—å–Ω–µ–π—à–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç. –ù–∞–ø–∏—à–∏—Ç–µ –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º –≤—ã–ø–æ–ª–Ω–∏—Ç –∑–∞–ø—Ä–æ—Å.\n",
    "\n",
    "### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n",
    "{}\n",
    "\n",
    "### –í–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:\n",
    "{}\n",
    "\n",
    "### –û—Ç–≤–µ—Ç:\n",
    "{}\"\"\"\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –∑–∞–¥–∞—á—É \"–†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞\"\n",
    "EOS_TOKEN = tokenizer.eos_token # –∫–æ–Ω–µ—á–Ω—ã–π —Ç–æ–∫–µ–Ω —É —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ Qwen\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"input\"]\n",
    "    outputs = examples[\"output\"]\n",
    "    texts = []\n",
    "    # –°–æ–∑–¥–∞—ë–º —Å—ç–º–ø–ª –ø–æ —à–∞–±–ª–æ–Ω–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É, –≤ –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –æ—Å—Ç–∞–Ω–æ–≤–∫–∏\n",
    "    for input, output in zip(inputs, outputs):\n",
    "        text = alpaca_prompt.format(\"–†–µ–∑—é–º–∏—Ä—É–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω—ë–º –≤ –∫—Ä–∞—Ç–∫–æ–º –æ–±—ä—ë–º–µ.\", input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets # —Ä–∞–±–æ—Ç–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏ HF\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "def prepare_sets(ds_repo: str, name: str, revision: str, split: str):\n",
    "    ds = load_dataset(ds_repo, name=name, revision=revision, split=split) # –∑–∞–≥—Ä—É–∑–∫–∞ —Å —Å–µ—Ä–≤–µ—Ä–∞\n",
    "    ds = ds.remove_columns([x for x in ds.column_names if x not in ('text', 'summary')]) # —É–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤\n",
    "    ds = ds.rename_columns({\"text\": \"input\", \"summary\": \"output\"})  # –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –ø–æ–¥ –æ–±—â–∏–π —Ñ–æ—Ä–º–∞—Ç\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ:\n",
    "    ds = ds.filter(\n",
    "        lambda x: \n",
    "            len(x[\"input\"]) >= 512 and # 1) –¥–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ >= 512 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x[\"input\"]) <= max_seq_length and  # 2) –¥–ª–∏–Ω–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ <= 4096\n",
    "            len(x[\"output\"]) >= 20 and # 3) –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç >= 20 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x['output']) <= max_summary_length and  # 4) –†–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç <= 128 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "            len(x[\"output\"])/len(x[\"input\"]) < 0.3  # 5) –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä—ë–º–æ–≤ 2-—Ö —Ç–µ–∫—Å—Ç–æ–≤ <= 0.3\n",
    "    )\n",
    "\n",
    "    if split == 'test': # –ø—Ä–∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç\n",
    "        return ds\n",
    "    \n",
    "    ds = ds.map(formatting_prompts_func, batched=True) # –≤ –∏–Ω–æ–º —Å–ª—É—á–∞–µ —Ñ–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç\n",
    "\n",
    "    # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –¥–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ <= 4096 —Å–∏–º–≤–æ–ª–æ–≤\n",
    "    ds = ds.filter(\n",
    "        lambda x: len(x[\"text\"]) <= max_seq_length,\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = concatenate_datasets(\n",
    "    [\n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='train'), \n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='validation'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='train'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='validation')\n",
    "    ]\n",
    ")\n",
    "test_dataset = concatenate_datasets(\n",
    "    [\n",
    "        prepare_sets(ds_repo='IlyaGusev/gazeta', name=None, revision=\"v2.0\", split='test'),\n",
    "        prepare_sets(ds_repo='csebuetnlp/xlsum', name='russian', revision=None, split='test')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['input', 'output', 'text'],\n",
       "     num_rows: 38413\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['input', 'output'],\n",
       "     num_rows: 5520\n",
       " }))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –í–∑–≥–ª—è–µ–º –Ω–∞ –æ–±—ä—ë–º –¥–∞—Ç–∞—Å–µ—Ç–æ–≤\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    max_seq_length = max_seq_length,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        overwrite_output_dir = True,\n",
    "        num_train_epochs = 3,\n",
    "        per_device_train_batch_size = 32,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        learning_rate = 3e-4,\n",
    "        logging_steps = 10,\n",
    "        \n",
    "        warmup_ratio = 0.1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.01,\n",
    "        max_grad_norm = 0.8,\n",
    "        \n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        \n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    "        save_steps=200,\n",
    "        torch_compile=True,\n",
    "        gradient_checkpointing=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 4070 Ti. Max memory = 11.994 GB.\n",
      "0.547 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 38,413 | Num Epochs = 3\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 128 | Total steps = 900\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Enabled auto compiling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [900/900 3:34:59, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.283700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.893700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.868600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.855300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.835100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.819500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.829300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.807800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.817900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.800700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.791300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.794600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.788100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.774600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.787900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.785900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.773800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.757100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.775100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.744900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.738700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.744400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.739400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.743300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.723600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.705600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.717700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.725200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.706800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.704600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.714900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.691500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.674400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.688700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.679100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.682000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.678500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.683300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.681900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.669600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.673100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.680100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.664900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.673200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen2_5_lora_sft_model/tokenizer_config.json',\n",
       " 'qwen2_5_lora_sft_model/special_tokens_map.json',\n",
       " 'qwen2_5_lora_sft_model/vocab.json',\n",
       " 'qwen2_5_lora_sft_model/merges.txt',\n",
       " 'qwen2_5_lora_sft_model/added_tokens.json',\n",
       " 'qwen2_5_lora_sft_model/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä\n",
    "model.save_pretrained(\"qwen2_5_lora_sft_model\")\n",
    "tokenizer.save_pretrained(\"qwen2_5_lora_sft_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12916.6526 seconds used for training.\n",
      "215.28 minutes used for training.\n",
      "Peak reserved memory = 4.072 GB.\n",
      "Peak reserved memory for training = 3.525 GB.\n",
      "Peak reserved memory % of max memory = 33.95 %.\n",
      "Peak reserved memory for training % of max memory = 29.39 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory*100, 3)\n",
    "\n",
    "\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(input_txt: str, _model, _tokenizer):\n",
    "    _model = FastLanguageModel.for_inference(_model)\n",
    "    # –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –±–∞—Ç—á –¥–ª–∏–Ω–Ω–æ–π 1 –∏–∑ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏, \"–û—Ç–≤–µ—Ç: \" –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—à–∫–∏\n",
    "    inputs = _tokenizer(\n",
    "    [\n",
    "        alpaca_prompt.format(\n",
    "            \"–†–µ–∑—é–º–∏—Ä—É–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω—ë–º –≤ –∫—Ä–∞—Ç–∫–æ–º –æ–±—ä—ë–º–µ.\",\n",
    "            input_txt,\n",
    "            \"\",\n",
    "        )\n",
    "    ], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏–º –≤—ã—Ö–ª–æ–ø –º–æ–¥–µ–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ù–µ –∑–∞–±—ã–≤–∞–µ–º –¥–µ–ª–∞—Ç—å split, —á—Ç–æ–±—ã –Ω–µ –≤—ã–≤–æ–¥–∏—Ç—å –≤–µ—Å—å –ø—Ä–æ–º–ø—Ç\n",
    "    outputs = _model.generate(input_ids = inputs.input_ids, attention_mask = inputs.attention_mask,\n",
    "                            max_new_tokens=max_summary_length, use_cache=True)\n",
    "    return _tokenizer.batch_decode(outputs, skip_special_tokens=True)[0].split(\"### –û—Ç–≤–µ—Ç:\\n\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.2.9: Fast Qwen2 patching. Transformers: 4.48.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4070 Ti. Max memory: 11.994 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# –ì—Ä—É–∑–∏–º –±–∞–∑–æ–≤—É—é –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "model_base, tokenizer_base = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-0.5B\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")\n",
    "\n",
    "# –ì—Ä—É–∑–∏–º SFT –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞\n",
    "model_sft, tokenizer_sft = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"qwen2_5_lora_sft_model\",\n",
    "    attn_implementation = \"flash_attention_2\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "SFT model: \n",
      "--------------------------------------------------\n",
      "('–ü–æ–ª–∏—Ü–∏—è –£–∫—Ä–∞–∏–Ω—ã –∑–∞–¥–µ—Ä–∂–∞–ª–∞ –ø–æ–ª–∏—Ç–∏–∫–∞ –ú–∏—Ö–∞–∏–ª–∞ –°–∞–∞–∫–∞—à–≤–∏–ª–∏, –∫–æ—Ç–æ—Ä–æ–≥–æ –æ–±–≤–∏–Ω—è—é—Ç –≤ '\n",
      " '—Å–æ–¥–µ–π—Å—Ç–≤–∏–∏ –ø—Ä–µ—Å—Ç—É–ø–Ω—ã–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è–º –∏ –ø–æ—Å—è–≥–∞—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–∞ —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∞–ª—å–Ω—É—é '\n",
      " '—Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –£–∫—Ä–∞–∏–Ω—ã.')\n",
      "--------------------------------------------------\n",
      "Base model: \n",
      "--------------------------------------------------\n",
      "('–ü–æ—Å–ª–µ –∑–∞–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ–ª–∏—Ç–∏–∫–∞ –°–∞–∞–∫–∞—à–≤–∏–ª–∏ –≤ –∫–∏–µ–≤—Å–∫–æ–º —Ä–µ—Å—Ç–æ—Ä–∞–Ω–µ \"–°—É–ª—É–≥—É–Ω–∏\" –±—ã–ª '\n",
      " '–∑–∞–¥–µ—Ä–∂–∞–Ω –∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –≤ –±—É—Å, –∑–∞—Ç–µ–º –ø–æ–≤–µ–∑–ª–∏ –∏ –∑–∞—Ç–µ–º –ø–æ—Å–∞–¥–∏–ª–∏ –≤ –≤–µ—Ä—Ç–æ–ª–µ—Ç. '\n",
      " '–í–µ—Ä—Ç–æ–ª–µ—Ç, –∫–∞–∫ —è –ø–æ–Ω–∏–º–∞—é, –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è –∫—Ä—É–∂–∏–ª –Ω–∞–¥ –ö–∏–µ–≤–æ–º. –ü–æ—Å–ª–µ —á–µ–≥–æ '\n",
      " '–ø—Ä–∏–∑–µ–º–ª–∏–ª—Å—è –≤ –ë–æ—Ä–∏—Å–ø–æ–ª–µ, –≥–¥–µ –º–µ–Ω—è, —Å–∫—Ä—É—Ç–∏–≤ —Ä—É–∫–∏ –∏ —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –≥—Ä—É–±–æ–π —Å–∏–ª—ã, '\n",
      " '–ø–æ—Å–∞–¥–∏–ª–∏ –≤ —Å–∞–º–æ–ª–µ—Ç.')\n",
      "--------------------------------------------------\n",
      "Ground truth: \n",
      "--------------------------------------------------\n",
      "('–ë—ã–≤—à–∏–π –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –ì—Ä—É–∑–∏–∏ –∏ —ç–∫—Å-–≥—É–±–µ—Ä–Ω–∞—Ç–æ—Ä –û–¥–µ—Å—Å–∫–æ–π –æ–±–ª–∞—Å—Ç–∏ –£–∫—Ä–∞–∏–Ω—ã –ú–∏—Ö–∞–∏–ª '\n",
      " '–°–∞–∞–∫–∞—à–≤–∏–ª–∏, –∫–æ—Ç–æ—Ä—ã–π –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ –≤—ã—Å—Ç—É–ø–∞–µ—Ç —Å –∫—Ä–∏—Ç–∏–∫–æ–π –≤ –∞–¥—Ä–µ—Å '\n",
      " '—É–∫—Ä–∞–∏–Ω—Å–∫–æ–≥–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ –ü–µ—Ç—Ä–∞ –ü–æ—Ä–æ—à–µ–Ω–∫–æ, –≤—ã—Å–ª–∞–Ω –∏–∑ –ö–∏–µ–≤–∞ –≤ –ü–æ–ª—å—à—É.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint # –∫—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥\n",
    "from random import choice # –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–Ω–¥–æ–º–Ω–æ–≥–æ —Å—ç–º–ø–ª–∞ –∏–∑ –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "# –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —Å—ç–º–ø–ª –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "random_idx = choice(range(0, len(test_dataset)))\n",
    "random_text = test_dataset['input'][random_idx]\n",
    "random_output = test_dataset['output'][random_idx]\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —É 2-—Ö –º–æ–¥–µ–ª–µ–π\n",
    "predicted_output_pretrained = inference(random_text, model_sft, tokenizer_sft)\n",
    "predicted_output_base = inference(random_text, model_base, tokenizer_base)\n",
    "\n",
    "# –í—ã–≤–æ–¥ –≤—ã—Ö–ª–æ–ø–∞ –º–æ–¥–µ–ª–µ–π –∏ ground truth\n",
    "print('-' * 50)\n",
    "print(\"SFT model: \")\n",
    "print('-' * 50)\n",
    "pprint(predicted_output_pretrained)\n",
    "\n",
    "print('-' * 50)\n",
    "print(\"Base model: \")\n",
    "print('-' * 50)\n",
    "pprint(predicted_output_base)\n",
    "\n",
    "print('-' * 50)\n",
    "print('Ground truth: ')\n",
    "print('-' * 50)\n",
    "pprint(random_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é SFT —è –≤ —Ü–µ–ª–æ–º –¥–æ–≤–æ–ª–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º:\n",
    "1) –ú–æ–¥–µ–ª—å –Ω–∞—É—á–∏–ª–∞—Å—å —Å–ª–µ–¥–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç—É –ø—Ä–æ–º–ø—Ç–æ–≤\n",
    "2) –õ—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Ä—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç\n",
    "3) –£–ª–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–∏\n",
    "4) –•–æ—Ç—å –æ—Ç–≤–µ—Ç—ã –∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç GT, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –≥–ª–∞–≤–Ω–∞—è –º—ã—Å–ª—å —Ç–µ–∫—Å—Ç–∞ –ø–µ—Ä–µ–¥–∞–Ω–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°—Ä–∞–≤–Ω–∏–≤–∞—è –±–∞–∑–æ–≤—ã–π **Qwen2.5-0.5B** –∏ **SFT Qwen2.5-0.5B**:\n",
    "* –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–æ–≤–æ–ª—å–Ω–æ –ø–ª–æ—Ö–æ —Å–ª–µ–¥—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –∏ –Ω–µ –¥–µ–ª–∞–µ—Ç —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —á—Ç–æ —á–∞—Å—Ç–æ –æ–±—Ä–µ–∑–∞–µ—Ç—Å—è —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–æ–º –ø–æ –¥–ª–∏–Ω–µ —Å—Ç—Ä–æ–∫–∏. –ù–µ —Å–æ–±–ª—é–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–º–ø—Ç–∞, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç. –ë—ã–≤–∞–µ—Ç —á–∞—Å—Ç–æ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–∏, –µ—Å–ª–∏ –Ω–µ —Å—Ç–∞–≤–∏—Ç—å –±–æ–ª—å—à–æ–π ```reputatuin_penality```.\n",
    "\n",
    "* –í —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å SFT –º–æ–¥–µ–ª—å –ø–æ–Ω–∏–º–∞–µ—Ç —Å–≤–æ—é –∑–∞–¥–∞—á—É, –¥–µ–ª–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ –∏ —Å–æ–±–ª—é–¥–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞. –í—Å–µ–≥–¥–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ù–µ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.\n",
    "\n",
    "## –ì–æ–≤–æ—Ä—è –æ –ø–ª—é—Å–∞—Ö SFT –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:\n",
    "1) –ú–∞–ª–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ VRAM (—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏)\n",
    "2) –î–æ–≤–æ–ª—å–Ω–æ –±—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ (—Å–ø–∞—Å–∏–±–æ, –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –æ—Ç unsloth)\n",
    "3) –ù–µ—Ç—Ä–µ–±–æ–≤–∞—Ç–µ–ª—å–Ω–∞ –∫ gold-–¥–∞–Ω–Ω—ã–º, —Ç–∞–∫ –∫–∞–∫ —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ —Å–∏–ª—å–Ω–æ –ø–æ—Ä—Ç–∏—Ç –º–æ–¥–µ–ª—å, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º —Ö–æ—Ç—å –∫–∞–∫–∞—è-—Ç–æ –ø–æ–ª–µ–∑–Ω–∞—è –¥–∞—Ç–∞ –±—É—Å—Ç–∏—Ç –º–æ–¥–µ–ª—å.\n",
    "\n",
    "## –ì–æ–≤–æ—Ä—è –æ –º–∏–Ω—É—Å–∞—Ö SFT –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:\n",
    "1) –ù—É–∂–Ω–æ –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ –∏ –¥–ª—è –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–∫)\n",
    "2) –ü–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π RL –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ—Å–ª–µ SFT (–Ω–∞–ø—Ä–∏–º–µ—Ä PPO/GRPO –∏ –ø—Ä–æ—á–∏–µ policy) –≤—Ä—è–¥ –ª–∏ –≤—ã–π–¥–µ—Ç.\n",
    "3) –õ—É—á—à–µ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–µ–±—è LLM –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —Ö–æ—Ç—è –±—ã —Å >1.5B –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –±—ã—Å—Ç—Ä–µ–µ —É–ª–∞–≤–ª–∏–≤–∞—é—Ç –∑–∞–¥–∞—á—É –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
